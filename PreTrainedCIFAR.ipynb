{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreTrainedCIFAR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH2Rquai1VR1",
        "colab_type": "code",
        "outputId": "490912aa-0d7f-465a-c085-10a64e77c640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vorULioq1eKi",
        "colab_type": "code",
        "outputId": "cb29a5e8-0d36-41d4-f376-d44b73221d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dd7_HBr2Y1s",
        "colab_type": "code",
        "outputId": "747775b4-a211-48fb-f442-cebeae026b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDv5tivg2gvx",
        "colab_type": "code",
        "outputId": "818497f4-d0b0-4747-fd61-035489fa0228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY1RJRgb2vQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u1nGym5dLLBb",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "model = models.Sequential()\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPVQ_Ve3XzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8rCzag03Vdj",
        "colab_type": "code",
        "outputId": "324cc6ec-e89a-43af-e083-67f5d174ddd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=20, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 3684s 74ms/sample - loss: 0.2411 - acc: 0.9189 - val_loss: 0.3250 - val_acc: 0.9000\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 3695s 74ms/sample - loss: 0.1937 - acc: 0.9364 - val_loss: 0.3251 - val_acc: 0.9000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 3701s 74ms/sample - loss: 0.1899 - acc: 0.9399 - val_loss: 0.3250 - val_acc: 0.9000\n",
            "Epoch 4/5\n",
            "49980/50000 [============================>.] - ETA: 1s - loss: 0.1935 - acc: 0.9412"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFDj3ZlrehWb",
        "colab_type": "code",
        "outputId": "7eb87440-8d96-4f51-929a-a38c3990bb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_acc = model.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 643s 64ms/sample - loss: 0.3803 - acc: 0.9000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gY9qOKZedty",
        "colab_type": "code",
        "outputId": "85cb003e-f9b0-4fc2-a45b-e357b40f10c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d_5 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  2097216   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  650       \n",
            "=================================================================\n",
            "Total params: 25,685,578\n",
            "Trainable params: 2,097,866\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0UE6n1Gdyr5",
        "colab_type": "code",
        "outputId": "260632db-0048-4caf-89ab-a7960ca42a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss_values, 'b', label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy', c='orange')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f50f6f5b358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAEWCAYAAABCNYfGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF+AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drOi2DKTgB8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}